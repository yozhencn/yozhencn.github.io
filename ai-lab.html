<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI æ¨¡å‹äº’å‹•å¯¦é©—å®¤</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="style.css" rel="stylesheet" type="text/css" />
  <style>
    body { font-weight: 500; }
    .section-title {
      font-size: 2rem;
      font-weight: 700;
      text-align: center;
      margin-bottom: 2rem;
      color: #2c3e50;
      position: relative;
    }
    .section-title::after {
      content: "";
      display: block;
      width: 50px;
      height: 3px;
      background: #4ecdc4;
      margin: 10px auto 0;
    }
    .img-preview {
      max-width: 100%;
      border-radius: 15px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
      margin-bottom: 1rem;
    }
    details {
      position: relative;
      background: #f8f9fa;
      padding: 1.5rem;
      border-radius: 15px;
      margin-bottom: 2rem;
    }
    details summary {
      font-weight: 600;
      font-size: 1.1rem;
      cursor: pointer;
      margin-bottom: 1rem;
    }
    details pre {
      margin: 0;
      overflow-x: auto;
      white-space: pre-wrap;
    }
    .copy-btn {
      position: absolute;
      top: 1.5rem;
      right: 1.5rem;
      font-size: 0.875rem;
      padding: 0.4rem 0.75rem;
      border: none;
      border-radius: 6px;
      background-color: #81C0C0;
      color: white;
      cursor: pointer;
      font-weight: 600;
    }
    .copy-btn:hover {
      background-color: #6ba7a7;
    }
  </style>
</head>
<body>
  <header class="bg-light py-4 border-bottom">
    <div class="container text-center">
      <h1 class="display-5 fw-bold">AI æ¨¡å‹äº’å‹•å¯¦é©—å®¤</h1>
      <p class="lead text-muted">æ•´åˆ Teachable Machineã€Streamlit èˆ‡ Local LLM çš„æ™ºæ…§æ‡‰ç”¨å¹³å°</p>
    </div>
  </header>

  <main class="container mt-5">
    <section class="mb-5">
      <h2 class="section-title">ğŸ“¸ Teachable Machine æ¨¡å‹å±•ç¤º</h2>
      <p class="text-center">é€éç€è¦½å™¨å°±èƒ½è¨“ç·´å½±åƒåˆ†é¡æ¨¡å‹ï¼Œä¸¦å³æ™‚æ‡‰ç”¨æ–¼é¡é ­è¾¨è­˜ã€‚</p>
      <div class="text-center mb-4 d-flex justify-content-center gap-4 flex-wrap">
        <div style="width: 45%;">
          <img src="attached_assets/teachable.png" alt="Teachable ç¤ºæ„" class="img-preview">
          <p class="mt-2">ğŸ‘‰ è¨“ç·´å¾Œçš„æ¨¡å‹å¯ç›´æ¥æ‡‰ç”¨æ–¼å¯¦é«”è¾¨è­˜ï¼Œç°¡å–®ç›´è¦ºã€‚</p>
        </div>
        <div style="width: 45%;">
          <img src="attached_assets/watch.png" alt="è¾¨è­˜æ‰‹éŒ¶" class="img-preview">
          
        </div>
      </div>
      
      <div class="text-center mt-3">
        <a href="models.html" class="btn btn-teal">æˆ‘ä¹Ÿæƒ³è©¦è©¦</a>
      </div>


      </div>
      </section>
      <details>
        <summary>â–¶ï¸ Teachable Machine ç¨‹å¼ç¢¼å±•ç¤º</summary>
        <button class="copy-btn" onclick="copyCode(this)">è¤‡è£½ç¨‹å¼ç¢¼</button>
        <pre><code>import tensorflow as tf
import cv2
import numpy as np

model = tf.keras.models.load_model('models/keras_model.h5', compile=False)
data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)

cap = cv2.VideoCapture(0)
while cap.isOpened():
    success, image = cap.read()
    img = cv2.resize(image , (224, 224))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    image = cv2.flip(image, 1)
    image_array = np.asarray(img)
    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1
    data[0] = normalized_image_array
    prediction = model.predict(data)
    a,b,c,d = prediction[0]
    if a>0.5:
        print('phone')
        cv2.putText(image, 'phone', (30, 120), 1, 3, (255,0,255), 10, 1)
    if b>0.5:
        print('drink')
        cv2.putText(image, 'drink', (130, 120), 1, 3, (255,0,0), 10, 1)
    if c>0.5:
        print('watch')
        cv2.putText(image, 'watch', (230, 120), 1, 3, (0,0,255), 10, 1)
    cv2.imshow('B11108032_gesture3', image)
    if cv2.waitKey(500) & 0xFF == 27:
        break
cap.release()</code></pre>
      </details>
    </section>

    <section class="mb-5">
      <h2 class="section-title">ğŸ–¥ï¸ Streamlit å±•ç¤ºå¹³å°</h2>
      <p class="text-center">åˆ©ç”¨ Streamlit å¿«é€Ÿå»ºç«‹æ¨¡å‹æ“ä½œä»‹é¢ï¼Œè®“ä½¿ç”¨è€…èˆ‡ AI å³æ™‚äº’å‹•ã€‚</p>
      <div class="text-center mb-4">
        <img src="attached_assets/streamlit.png" alt="Streamlit UI ç¤ºæ„åœ–" class="img-preview">
        <p>ğŸ¯ ä½¿ç”¨è€…å¯è¼¸å…¥å…§å®¹ã€ä¸Šå‚³åœ–ç‰‡æˆ–é¸æ“‡é¸é …ï¼Œå³å¯è§¸ç™¼æ¨¡å‹æ¨è«–ã€‚</p>
      </div>
      <details>
        <summary>â–¶ï¸ Streamlit YouTube ç‰©ä»¶è¾¨è­˜ç¨‹å¼ç¢¼</summary>
        <button class="copy-btn" onclick="copyCode(this)">è¤‡è£½ç¨‹å¼ç¢¼</button>
        <pre><code>base_options = mp.tasks.BaseOptions('models/efficientdet_lite0.tflite')
options = mp.tasks.vision.ObjectDetectorOptions(base_options, score_threshold=0.2)
detector = mp.tasks.vision.ObjectDetector.create_from_options(options)

video_url = "https://www.youtube.com/watch?v=UCG1aXVO8H8"
ydl_opts = {'format': 'best',  'quiet': True }
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info_dict = ydl.extract_info(video_url, download=False)
stream_url = info_dict['url']

cap = cv2.VideoCapture(stream_url)

st.title('Streamlit + CV2')
run = st.checkbox('Run')
FRAME_WINDOW = st.image([])

while run:
    success, image = cap.read()
    image = cv2.resize(image, (600, 360))
    image_mp = mp.Image(mp.ImageFormat.SRGB, image)
    detection_result = detector.detect(image_mp)
    for detection in detection_result.detections:
        bbox = detection.bounding_box
        cv2.rectangle(image, (bbox.origin_x, bbox.origin_y),
                      (bbox.origin_x + bbox.width, bbox.origin_y + bbox.height), (100, 200, 0), 1)
        category = detection.categories[0]
        result_text = category.category_name + ' (' + str(round(category.score, 2)) + ')'
        cv2.putText(image, result_text, (10 + bbox.origin_x, 20 + bbox.origin_y),
                    1, 1, (255, 255, 255), 1)
    FRAME_WINDOW.image(image, channels='BGR')
cap.release()</code></pre>
      </details>
    </section>

    <section class="mb-5">
      <h2 class="section-title">ğŸ§  Local LLM åœ¨åœ°å¤§è…¦</h2>
      <p class="text-center">ä¸éœ€é€£ç¶²å³å¯åŸ·è¡Œèªè¨€æ¨¡å‹ï¼Œæ”¯æ´èªéŸ³ã€æ–‡å­—èˆ‡åœ–åƒç†è§£ã€‚</p>

      <div class="text-center mb-4">
        <img src="attached_assets/voice.png" alt="æ–‡å­—èˆ‡èªéŸ³è™•ç†" class="img-preview">
        <p>ğŸ—£ï¸ å¯å°‡èªéŸ³è½‰ç‚ºæ–‡å­—ï¼Œä¸¦ç”¨æœ¬åœ° LLM å›è¦†ä½ çš„å•é¡Œã€‚</p>
      </div>
      <details>
        <summary>â–¶ï¸ Local LLM èªéŸ³è½‰æ–‡å­— + å›è¦† TTS</summary>
        <button class="copy-btn" onclick="copyCode(this)">è¤‡è£½ç¨‹å¼ç¢¼</button>
        <pre><code># streamlit run AI11_llm2.py
import streamlit as st
import ollama
from gtts.lang import tts_langs
from gtts import gTTS
import base64
from tempfile import NamedTemporaryFile

langs = tts_langs().keys()
st.title("Gemma3 æ–‡å­—èªéŸ³LLM TTSæ‡‰ç”¨ç¯„ä¾‹")
lang = st.selectbox("Please choose the language", options=langs, index=12)
user_input = st.text_area("è©¢å•ä»»ä½•å•é¡Œï¼š", "")

if st.button("send"):
    if user_input:
        st.markdown("<span style='color:red;'>è«‹ç¨å¾…ç‰‡åˆ»ï¼Œgemma3:1bæ€è€ƒä¸­...</span>", unsafe_allow_html=True)
        response = ollama.chat(model='gemma3:1b', messages=[{'role': 'user', 'content': user_input}])
        st.write(response['message']['content'])
        tts = gTTS(response['message']['content'], lang=lang, slow=False, lang_check=True)
        with NamedTemporaryFile(suffix=".mp3", delete=False) as temp:
            tts.save(temp.name)
            with open(temp.name, "rb") as f:
                data = f.read()
                b64 = base64.b64encode(data).decode()
                md = f"""<audio controls autoplay="true">
                     <source src="data:audio/mp3;base64,{b64}" type = "audio/mp3">
                     your browser does not support the audio element. </audio>"""
                st.markdown(md, unsafe_allow_html=True)
    else:
        st.warning("PLease type in your question!")</code></pre>
      </details>

      <div class="text-center mb-4 mt-5">
        <img src="attached_assets/park.png" alt="åœ–ç‰‡èªªæ˜åŠŸèƒ½" class="img-preview">
        <p>ğŸ“· æœ¬åœ°æ¨¡å‹ä¹Ÿèƒ½ç†è§£åœ–ç‰‡å…§å®¹ä¸¦é€²è¡Œèªªæ˜æˆ–å›ç­”ã€‚</p>
      </div>
      <details>
        <summary>â–¶ï¸ Local LLM åœ–ç‰‡è¼”åŠ©ç†è§£ï¼ˆå¤šæ¨¡æ…‹ï¼‰</summary>
        <button class="copy-btn" onclick="copyCode(this)">è¤‡è£½ç¨‹å¼ç¢¼</button>
        <pre><code>import streamlit as st
import ollama
import random

st.title("Gemma3 å¤šæ¨¡æ…‹ LLM æ‡‰ç”¨ç¯„ä¾‹")
colors = ['red', 'blue', 'green', 'orange', 'purple']
user_input = st.text_input("è©¢å•ä»»ä½•å•é¡Œï¼š", "")
uploaded_image = st.file_uploader("å¯åŒæ™‚ä¸Šå‚³åœ–ç‰‡ï¼ˆjpg/pngï¼‰", type=["jpg", "jpeg", "png"])

if st.button("send"):
    if user_input or uploaded_image:
        st.markdown(f"<span style='color:{random.choice(colors)};'>è«‹ç¨å¾…ç‰‡åˆ»ï¼Œæ€è€ƒä¸­ï¼Œé¦¬ä¸Šå›ç­”...</span>", unsafe_allow_html=True)
        messages = []
        if uploaded_image:
            st.image(uploaded_image, caption="ä¸Šå‚³çš„åœ–ç‰‡å¦‚ä¸Šï¼Œè«‹ç­‰å¾…åˆ¤è®€çµæœ...", use_container_width=True)
            image_bytes = uploaded_image.getvalue()
            messages.append({'role': 'user', 'content': user_input, 'images': [image_bytes]})
        else:
            messages.append({'role': 'user', 'content': user_input})
        response = ollama.chat(model='gemma3:4b', messages=messages)
        st.write(response['message']['content'])
    else:
        st.warning("è«‹è¼¸å…¥promptæˆ–ä¸Šå‚³åœ–ç‰‡ï¼")</code></pre>
      </details>
    </section>

    <div class="text-center mb-5">
      <a href="index.html#projects" class="btn btn-teal me-2">â† è¿”å›ä½œå“é›†</a>
      <a href="index.html" class="btn btn-teal">â† è¿”å›é¦–é </a>
    </div>
  </main>

  <footer class="bg-dark text-white text-center py-3">
    <p>&copy; 2025 é™³åˆæº± - AI æ¨¡å‹æ‡‰ç”¨å±•ç¤º</p>
  </footer>

  <script>
    function copyCode(button) {
      const code = button.nextElementSibling.querySelector('code').innerText;
      navigator.clipboard.writeText(code).then(() => {
        button.innerText = "âœ… å·²è¤‡è£½";
        setTimeout(() => (button.innerText = "è¤‡è£½ç¨‹å¼ç¢¼"), 2000);
      });
    }
  </script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
